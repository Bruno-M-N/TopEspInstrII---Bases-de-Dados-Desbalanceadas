% METODOLOGIA EXPERIMENTAL

% Texto principal.

% Texto principal. Para cada trabalho experimental deve descrever inicialmente o aparato experimental utilizado – com diagrama de blocos resumido do sistema desenvolvido (uma figura bem apresentada ou foto coerente com a descrição dos itens que formam o aparato experimental). Depois abrir em subcapítulos e descrever os principais itens do experimento desenvolvido ou projeto desenvolvido. \textbf{Este capítulo não deve conter resultados} e sim a descrição do método/experimento desenvolvido. De forma geral e simples este capítulo deve apresentar “como foi feito” o experimento e evidentemente para isso deve descrever todo e qualquer item utilizado no experimento (cuidado apenas para não tornar o relatório infantil e “sem fundamentação científica” nos experimentos simples principalmente).

% Toda e qualquer figura e tabela deve conter a respectiva chamada no texto, por exemplo, a Figura~\ref{diagrama_blocos} apresenta o diagrama de blocos do experimento desenvolvido para calibrar...etc. A Tabela \ref{tabela_tabuadas} apresenta os dados....etc. Equações também devem seguir a seguinte formatação (utilizar um bom editor de equações) e as mesmas devem ser numeradas sequencialmente no texto. Por exemplo:

% % No parágrafo acima, o trecho Figura~\ref{diagrama_blocos} está com um ~ antes da referência. Isso faz com que a palavra antecedente (Figura) não fique separada em 2 linhas, caso não haja espaço na mesma linha. Nesse caso, isso acontecerá se o ~ for removido.

% \begin{equation}
%     V = R * i
% \label{equação_ohm}
% \end{equation}

% Por exemplo, a Equação \ref{equação_ohm} representa a...etc.... onde V representa a tensão elétrica [V], R a resistência elétrica [Ω] e i....

% Texto principal. Todo e qualquer circuito devem conter a respectiva equação de medição....

% Texto principal. Programas desenvolvidos devem apresentar o fluxograma da rotina e a descrição dos principais blocos ou funções desenvolvidas e/ou utilizadas no corpo principal do texto (o restante pode ser colocado em um apêndice no final do relatório – não esquecer de apresentar a respectiva chamada, como por exemplo, a rotina principal do....bláblá.....encontra-se no Apêndice \ref{código_simples}. A Figura \ref{fluxograma_N} apresenta o fluxograma representando a rotina para ...... e descrever os principais blocos.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.5\textwidth]{Figuras/figura_exemplo.png}
%     \caption{Fluxograma representando a rotina desenvolvida no (...).\\\textbf{Fonte -} Fonte da figura.}
%     \label{fluxograma_N}
% \end{figure}

% \subsection{Sub-capítulo}
% Texto principal.

% Texto principal.

% \subsection{Sub-capítulo}
% Texto principal.

% Texto principal.

%%%%%%%%%%%%%%%%%%%%%%% Acima  Modelo %%%%%%%%%%%%%%%%%%%%%%%%



%%\subsection{Definição das especificações do instrumento}
% A fim de aplicar os conceitos relacionados ao desenvolvimento de Sistemas Especialistas com uso de lógica Fuzzy, são explorados $4$ projetos, cujas propostas e análises dos tratamentos são descrito a seguir.

% A fim de aplicar os conceitos relacionados ao desenvolvimento de \textit{Clusters}, são explorados $5$ exercícios, cujas propostas e análises dos tratamentos são descrito a seguir.

% Os dados coletados foram

% \subsection{Sistema fuzzy para automatizar um cultivo hidropônico de vegetais}

\subsection{Exercício i}

Foi selecionada a base de dados  \href{https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+\%28Diagnostic\%29}{Breast Cancer Wisconsin (Diagnostic) Data Set} \citep{wolberg_uci_1995}
 disponível em \url{https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+\%28Diagnostic\%29}.

Esse conjunto de dados da área oncológica contempla análise de células tumorais com base em imagens digitalizadas. As características, $32$, são obtidas a partir de uma imagem digitalizada de uma Punção aspirativa por agulha fina (PAAF, do inglês \textit{Fine-needle aspiration} - FNA) de uma massa mamária. Eles descrevem as características dos núcleos celulares presentes na imagem.

% contempla medições do consumo de energia elétrica em uma residência com uma taxa de amostragem de um minuto ao longo de um período de quase $4$ anos. Diferentes quantidades elétricas e alguns valores de sub-medição estão disponíveis.

% Este arquivo contém $569$ medidas reunidas em uma casa localizada em Sceaux ($7$ km de Paris, França) entre dezembro de $2006$ e novembro de $2010$ ($47$ meses). 
A Tabela \ref{tab:Diagnostic-Wisconsin-Breast-Cancer-Database} reúne algumas informações sobre o conjunto de dados.

\input{Tabelas/Diagnostic-Wisconsin-Breast-Cancer-Database}

% Observações:
% \begin{enumerate}
%     \item (global\_active\_power $\cdot 1000/60$ - sub\_metering\_1 - sub\_metering\_2 - sub\_metering\_3) representa a energia ativa consumida a cada minuto (em watt hora) na casa por equipamentos elétricos não medidos nos sub-medidores 1, 2 e 3.
    
%     \item O conjunto de dados contém alguns valores ausentes nas medições (quase $1,25\%$ das linhas). Todos os carimbos de tempo do calendário estão presentes no conjunto de dados, mas para alguns carimbos de tempo, os valores de medição estão faltando: um valor faltante é representado pela ausência de valor entre dois separadores consecutivos de atributos ponto-e-vírgula. Por exemplo, o conjunto de dados mostra valores ausentes em $28$ de abril de $2007$.
% \end{enumerate}

Informação dos Atributos:

Cada imagem possui um número de identificação e um diagnóstico, sendo $M$ para maligno e $B$ para benigno. Os outros $30$ atributros estão relacionados a dez características de valor real que são computadas para cada núcleo de célula:

\begin{enumerate}
    \item \textit{radius} - raio (média das distâncias do centro aos pontos do perímetro);
	\item \textit{texture} - textura (desvio padrão dos valores da escala de cinza);
	\item \textit{perimeter} - perímetro;
	\item \textit{area} - área;
	\item \textit{smoothness} - suavidade (variação local em comprimentos de raio);
	\item \textit{compactness} - compacidade ($\text{perímetro}^2$ / área - $1,0$);
	\item \textit{concavity} - concavidade (gravidade das porções côncavas do contorno);
	\item \textit{concave points} - pontos côncavos (número de porções côncavas do contorno);
	\item \textit{symmetry} - simetria ;
	\item \textit{fractal dimension} - dimensão fractal ("aproximação da linha de costa" - $1$).
\end{enumerate}

\cite{street_nuclear_1999} aponta que o valor médio (\textit{mean value}), maior valor (\textit{extreme, largest value} e erro padrão (\textit{standard error}) são determinados para cada imagem, sendo os valores extremos os mais intuitivamente úteis, uma vez que apenas algumas poucas células malignas pode ocorrer em uma determinada amostra.

Todas as características foram registradas com $4$ dígitos significativos. Não há valores ausentes e a classe é desbalanceada. Há $357$ tumores benignos e $212$ malignos.

\subsubsection{Análise do conjunto de dados coletado}

Para esta análise foi utilizada a linguagem de programação Python v$3.7.13$ na plataforma Google Colab. As bibliotecas  presentes na Tabela \ref{tab: bibliotecas-python} foram utilizadas:

\input{Tabelas/bibliotecas-python}

% Neste processo, foram fusionadas as colunas 'Date' e 'Time' do conjunto de dados original. Essa nova coluna foi utilizada como index do DataFrame.  

% Conforme \href{pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html}{pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to\_datetime.html}, definir o parâmetro \textit{infer\_datatime\_format} como verdadeiro pode aumentar a velocidade da etapa de \textit{parsing} entre $5$ à $10$ vezes, de modo que esse parametro foi setado.

% Os pontos de '?' presentes no dataset para o caso de ausência de dados foram transformados em \textit{numpy.nan}, afim de que todas os elementos fossem de um único tipo (ponto flutuante, no caso).

\subsection{Exercício ii}

Este exercício consiste executar e avaliar o código fornecido para construir um pipeline de um modelo inteligente qualquer para classificar os dados desbalanceados do \textit{dataset}.

Inicialmente, foram carregados os dados através da função \textit{read\_csv} do módulo \href{https://pandas.pydata.org/}{\textit{pandas}} em uma estrutura DataFrame deste.

As características de cada observação foram foram armazenadas em um Dataframe ($X$), enquanto os rótulos ($y$), foram armazenados em uma estrutura Series do módulo \textit{pandas}.

A classe \textit{\href{https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html}{LabelEncoder}} do \href{https://scikit-learn.org/stable/index.html}{\textit{scikit-learn}} \citep{scikit-learn} foi utilizada para codificar etiquetas dos rótulos 'M' e 'B' nos valores $0$ e $1$.

Os dados são então divididos através da função \href{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html}{\textit{train\_test\_split}}, com a proporção de $80\%$ dos dados para o conjunto de treinamento e $20\%$ para o conjunto de teste. As frequências relativas de classe são aproximadamente preservadas em cada conjunto de treinamento e teste, através da passagem de $y$ para o parâmetro \textit{stratify}.

Em seguida, uma pipeline, isto é, uma estrutura contendo uma lista de transformações com um estimador final é elaborada para o processamento dos dados. Para tal, é utilizada a classe \href{https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline}{\textit{Pipeline}} do \textit{scikit-learn}.  

Ela é construída através do método \href{https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html}{\textit{make\_pipeline}} e  contempla as seguintes classes do \textit{scikit-learn}:
\begin{itemize}
    \item normalização dos dados através da \href{https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html}{\textit{StandardScaler}}, que remove o valor médio das amostras (centralização) e realiza o escalonamento para variância unitária de cada característica;
    \item uma etapa de Análise de componentes principais (ACP) ou \textit{Principal Component Analysis} (PCA) para redução do número de características para duas componentes principais através da \href{https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html}{\textit{PCA}};
    \item classificador.
\end{itemize}

No caso do \textit{Exercício ii}, este classificador é baseado em uma regressão logística, utilizando-se para tal a classe \href{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html}{\textit{LogisticRegression}}.

Como métrica principal, inicialmente foi selecionada a \textit{accuracy}.

A função \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html}{\textit{classification\_report}} do módulo \textit{scikit-learn} foi utilizada, exibindo além da \textit{accuracy}, \textit{precision}, \textit{recall} e \textit{f1-score}.

As matrizes de confusão também são exibidas utilizando-se para tal a função \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html}{\textit{confusion\_matrix}} do módulo \textit{scikit-learn}.

\subsection{Exercício iii}

O \textit{Exercício iii} consiste em avaliar o impacto de outros modelos inteligentes pertinentes na classificação da base desbalanceada utilizada anteriormente.

% O código desenvolvido para cada modelo proposto e avaliar o impacto dos mesmos na classificação e evidentemente da base desbalanceada utilizada.

Dois modelos do módulo \textit{scikit-learn} foram selecionados:
\begin{itemize}
    \item classificador baseado em  Máquina de vetores de suporte (SVM, do inglês \textit{Support Vector Machine}) -  \href{https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn-svm-svc}{\textit{SVC}};
    \item classificador Random Forest, meta-classificador baseado em um conjunto de árvores de decisão - \href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}{\textit{RandomForestClassifier}}
\end{itemize}

Como destaca \citet{scikit-learn-svn}, a escolha de $C$ e gamma é crítica para a performance da SVM, sendo recomendado por exemplo o uso da pesquisa em rede com $C$ e gamma espaçados exponencialmente para escolha de parâmetros adequados.

Dessa forma, também foi utilizada uma pesquisa em rede para a obtenção de uma SVM otimizada para o problema.

A \textit{accuracy}, bem como a  matriz de confusão  e o \textit{classification\_report}, são analisados para esses modelos.

Os códigos baseados nos modelos foram disponibilizado nos anexos. Esses códigos foram gerados em \textit{notebooks} no Colab e foram transcritos em arquivo \textit{python} para fins exibição. Assim, por exemplo, o arquivo \textit{funcoes\_geracao\_tabelas\_LaTeX.py} não existia no Colab e não havia necessidade de realizar sua importação.

\subsection{Exercício iv}

Neste exercício, busca-se evidenciar o problema do desbalanceamento de dados.

São anexados verticalmente $40$ dados da classe $1$ (usando a função do \textit{numpy} \href{https://numpy.org/doc/stable/reference/generated/numpy.vstack.html}{\textit{vstack}}) à classe $0$ ($357$ amostras) gerando um total de $397$ instâncias ou dados. Da mesma forma, são anexados horizontalmente $40$ dados da classe $1$ (tumor maligno) aos $357$ dados da classe $0$ (tumor benigno) usando a função do numpy \href{https://numpy.org/doc/stable/reference/generated/numpy.hstack.html}{\textit{hstack}}.

Exibe-se então o percentual de instâncias pertencentes a primeira classe (com $357$ dados) do total.

Os dados são então divididos através da função \href{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html}{\textit{train\_test\_split}}, guardando-se a proporção de $80\%$ dos dados para o conjunto de treinamento e $20\%$ para o conjunto de teste. As frequências relativas de classe também são aproximadamente preservadas.

Na sequência, os dados passam pela mesma pipeline do \textit{Exercício ii}, com o classificador baseado em regressão logística. 

A \textit{accuracy}, bem como a  matriz de confusão  e o \textit{classification\_report}, são analisados para esse modelo.

\subsection{Exercício v}

Neste exercício, busca-se evidenciar a dependência da proporção do desbalanceamento de dados no desempenho de um modelo inteligente. Para tal, outras duas configurações de divisão saõ utilizadas, porém mantendo a classe $0$ com seu tamanho original, $357$ amostras do dataset original, ou seja, com a adição de um número de dados $z$ da classe $1$ anexados a cada array.

Foram utilizados $z$ igual à $80$ e $120$, que podem ser comparados ao exercício anterior, onde $z = 40$ e ao \textit{Exercício ii}, para o qual $z = 212$ 

Os demais procedimentos são análogos ao do \textit{Exercício iv}.

\subsection{Exercício vi}

A função \href{https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html}{\textit{resample}} do módulo \textit{scikit-learn} para re-amostragem de dados pode ser utilizada para auxiliar no problema relacionado as classes desbalanceadas ou ao menos apresentar o resultado de uma métrica de desempenho “mais realista” ao problema de interesse.

Esta função pode auxiliar com o upsampling da classe minoritária. Nesse caso, estamos “criando” novas amostras sintéticas ao conjunto de dados.

Exibe-se então o percentual de instâncias pertencentes a classe $1$ (minoritária) antes e após a reamostragem, que dá origem a um total de $357$ dados para a classe $1$, totalizando $714$ dados das duas classes.

Um novo array é criado através da função do \textit{numpy} \href{https://numpy.org/doc/stable/reference/generated/numpy.vstack.html}{\textit{vstack}}, pela qual são anexados verticalmente os dados da classe $0$ com os dados reamostrados da classe $1$.  Da mesma forma, são anexados horizontalmente os dados da classe $1$ (tumor maligno) reamostrados aos $357$ dados da classe $0$ (tumor benigno) usando a função do \textit{numpy} \href{https://numpy.org/doc/stable/reference/generated/numpy.hstack.html}{\textit{hstack}}.

Os dados são então divididos através da função \href{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html}{\textit{train\_test\_split}}, guardando-se a proporção de $80\%$ dos dados para o conjunto de treinamento e $20\%$ para o conjunto de teste. As frequências relativas de classe também são aproximadamente preservadas.

Na sequência, os dados passam pela mesma pipeline do \textit{Exercício ii}, com o classificador baseado em regressão logística. 

A \textit{accuracy}, bem como a  matriz de confusão  e o \textit{classification\_report}, são analisados para esse modelo.
% Abrir o ambiente de programação Python, digitar o correspondente código e analisar o mesmo 

\subsection{Exercício vii}

Também seria possível reduzir o tamanho amostral da classe Majoritária (classe $0$) para a etapa de treinamento.

A função \href{https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html}{\textit{resample}} é utilizada nesse caso para reduzir o número de elementos da classe $0$ até $212$. Para tanto, os elementos da classe $0$ de $X$ e de $y$ são passados para \textit{resample}, com o número de amostras definidos como o número de elementos da classe $1$, isto é $212$.

Exibe-se então o percentual de instâncias pertencentes a classe $0$ (minoritária) antes e após a reamostragem, totalizando $424$ dados das duas classes.

Um novo array é criado através da função do \textit{numpy} \href{https://numpy.org/doc/stable/reference/generated/numpy.vstack.html}{\textit{vstack}}), pela qual são anexados verticalmente os dados da classe $0$ com os dados reamostrados da classe $1$. Da mesma forma, são anexados horizontalmente os dados da classe $1$ (tumor maligno) aos $212$ dados da classe $0$ (tumor benigno) reamostrados usando a função do \textit{numpy} \href{https://numpy.org/doc/stable/reference/generated/numpy.hstack.html}{\textit{hstack}}.


Os dados são então divididos através da função \href{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html}{\textit{train\_test\_split}}, guardando-se a proporção de $80\%$ dos dados para o conjunto de treinamento e $20\%$ para o conjunto de teste. As frequências relativas de classe também são aproximadamente preservadas.

Na sequência, os dados passam pela mesma pipeline do \textit{Exercício ii}, com o classificador baseado em regressão logística. 

A \textit{accuracy}, bem como a  matriz de confusão  e o \textit{classification\_report}, são analisados para esse modelo.

\subsection{Exercício viii}

A base de dados desbalanceada com diversa informações socioeconômicas “adultoUCI.csv” \ foi disponibilizada aos alunos.

Este exercício consiste executar e avaliar o código fornecido para construir um pipeline de um modelo inteligente qualquer para classificar os dados desbalanceados do \textit{dataset}.

Inicialmente, foram carregados os dados através da função \textit{read\_csv} do módulo \href{https://pandas.pydata.org/}{\textit{pandas}} em uma estrutura DataFrame deste.

Após eliminação das linhas com valores ausentes, obtém-se o número de elementos de cada classe: aqueles que recebem um valor em uma dada unidade monetária menor ou igual à $50$ mil pertencerão a classe $0$, enquanto aqueles que recebem mais de $50$ mil pertencerão a classe $I$.


A classe \textit{\href{https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html}{LabelEncoder}} do \href{https://scikit-learn.org/stable/index.html}{\textit{scikit-learn}} \citep{scikit-learn} foi utilizada para codificar etiquetas dos rótulos de cada característica.


As características de cada observação foram foram armazenadas em um Dataframe ($X$), com exceção da característica de renda (\textit{income}),que corresponde ao rótulo ($y$), e foi armazenada em uma estrutura Series do módulo \textit{pandas}.

Os dados são então divididos através da função \href{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html}{\textit{train\_test\_split}}, com a proporção de $80\%$ dos dados para o conjunto de treinamento e $20\%$ para o conjunto de teste. 
% As frequências relativas de classe são aproximadamente preservadas em cada conjunto de treinamento e teste, através da passagem de $y$ para o parâmetro \textit{stratify}.

Em seguida, um classificador Random Forest (\href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}{\textit{RandomForestClassifier}}) é utilizado.

% Em seguida, uma pipeline, isto é, uma estrutura contendo uma lista de transformações com um estimador final é elaborada para o processamento dos dados. Para tal, é utilizada a classe \href{https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline}{\textit{Pipeline}} do \textit{scikit-learn}.  

% Ela é construída através do método \href{https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html}{\textit{make\_pipeline}} e  contempla as seguintes classes do \textit{scikit-learn}:
% \begin{itemize}
%     \item normalização dos dados através da \href{https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html}{\textit{StandardScaler}}, que remove o valor médio das amostras (centralização) e realiza o escalonamento para variância unitária de cada característica;
%     \item uma etapa de Análise de componentes principais (ACP) ou \textit{Principal Component Analysis} (PCA) para redução do número de características para duas componentes principais através da \href{https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html}{\textit{PCA}};
%     \item classificador.
% \end{itemize}

% No caso do \textit{Exercício ii}, este classificador é baseado em uma regressão logística, utilizando-se para tal a classe \href{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html}{\textit{LogisticRegression}}.

Como métrica principal, inicialmente foi selecionada a \textit{accuracy}.

A função \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.htmll}{\textit{classification\_report}} do módulo \textit{scikit-learn} foi utilizada, exibindo além da \textit{accuracy}, \textit{precision}, \textit{recall} e \textit{f1-score}.

A matrize de confusão também é exibida utilizando-se para tal a função \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html}{\textit{confusion\_matrix}} do módulo \textit{scikit-learn}.

\subsection{Exercício ix}

O \textit{Exercício ix} consiste em avaliar o impacto de outros modelos inteligentes pertinentes na classificação da base desbalanceada utilizada anteriormente.

% O código desenvolvido para cada modelo proposto e avaliar o impacto dos mesmos na classificação e evidentemente da base desbalanceada utilizada.

Dois modelos do módulo \textit{scikit-learn} foram selecionados:
\begin{itemize}
    \item classificador baseado em  Máquina de vetores de suporte (SVM, do inglês \textit{Support Vector Machine}) -  \href{https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn-svm-svc}{\textit{SVC}};
    \item classificador baseado em regressão Logística.
\end{itemize}

% Como destaca \citet{scikit-learn-svn}, a escolha de $C$ e gamma é crítica para a performance da SVM, sendo recomendado por exemplo o uso da pesquisa em rede com $C$ e gamma espaçados exponencialmente para escolha de parâmetros adequados.

Também foi utilizada pesquisa em rede para a obtenção de uma SVM otimizada para o problema, tendo em vista que, como destaca \citet{scikit-learn-svn}, a escolha de $C$ e gamma é crítica para a performance da SVM.

A \textit{accuracy}, bem como a  matriz de confusão  e o \textit{classification\_report}, são analisados para esses modelos.

Os códigos baseados nos modelos foram disponibilizado nos anexos. Esses códigos foram gerados em \textit{notebooks} no Colab e foram transcritos em arquivo \textit{python} para fins exibição. Assim, por exemplo, o arquivo \textit{funcoes\_geracao\_tabelas\_LaTeX.py} não existia no Colab e não havia necessidade de realizar sua importação.

\subsection{Exercício x}

A função \href{https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html}{\textit{compute\_class\_weight}} permite estimar o peso das classes em datasets desbalanceados.

De modo geral, os modelos inteligentes do módulo \textit{sckit-learn} possuem um parâmetro \textit{class\_weight} que permite atribuir uma penalidade para cada previsão errada relacionada a classe minoritária.

Desta forma, o \textit{Exercício viii} é revisitado, utilizando-se agora no  classificador Random Forest (\href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}{\textit{RandomForestClassifier}}) o parâmetro \textit{class\_weight} com os valores "\textit{balanced}" \ e "\textit{balanced\_subsample}".