% % RESULTADOS E DISCUSSÕES

% Texto principal. 

% Texto principal. Aqui devem ser apresentados todos os resultados do trabalho/experimento contendo tabelas, gráficos (figuras) e demais figuras necessárias à compreensão do trabalho/experimento. Todos os conceitos da área de instrumentação devem ser apresentados para cada sistema, como por exemplo, cadeia de medição, resolução, sensibilidade, erro de linearidade, erro de conformidade, etc... 

% Resumidamente este capítulo deve apresentar os resultados e discussões do que foi feito no capítulo anterior. Jamais uma figura ou tabela deve ficar “solta” no trabalho e a mesma deve ser chamada no texto e conter uma discussão coerente em relação à mesma. É desnecessário afirmar que figuras, tabelas e etc devem ser legíveis para a completa compreensão do texto. Uma boa forma para verificar a qualidade de um texto é deixar outra pessoa ler com atenção seu texto e verificar se a mesma compreendeu o texto! Além disso, sugiro a leitura várias vezes do relatório pelo grupo antes da sua entrega. Os resultados devem ser discutidos baseados nos conceitos de instrumentação – apresentar análise coerente dos dados (usando estatística, análise da propagação de incertezas, etc).

% \subsection{Sub-capítulo}

% Texto principal.

% Texto principal.

% Texto principal. Observe que todo e qualquer texto, figura(s), tabela(s) que não sejam originais dos autores devem obrigatoriamente ser apresentadas as correspondentes fontes (o mesmo vale para texto de outros autores). Devemos respeitar os direitos autorais para evitar possíveis problemas de ordem legal e penalidades em função disso. Por exemplo:

% Segundo \citet{vim2012vocabulario}, (citação quando o texto é de apenas um autor) texto texto texto. De acordo com \citet{balbinot2019instrumentacao}, texto texto texto (citação quando o texto é de dois autores). Para mais de dois autores usar et al., por exemplo, \citet{brockman2016gym}, texto texto....

% % Nesse documento LaTex, há 3 opções para fazer citação. São elas: \cite{} (separa o nome do(s) autor(es) e do ano por vírgula), \citet{} (ano em parentesis) e \citep{} (autor(es) e ano em parentesis).

% \input{Tabelas/tabela_exemplo}

% Adicionar a figura aqui. Se a figura não foi desenvolvida por vocês citar a fonte. Mesmo quando a figura foi alterada devemos citar que a mesma pertence ao autor original e foi adaptada livremente pelos autores do relatório. Obrigatoriamente toda e qualquer citação deve estar completa nas referência bibliográficas do relatório para consulta dos leitores.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.5\textwidth]{Figuras/diagrama_blocos.jpg}
%     \caption{Diagrama de blocos do experimento (...).\\\textbf{Fonte -} Fonte da figura.}
%     \label{diagrama_blocos}
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Exercício ii}

A \textit{accuracy} obtida neste modelo foi de $0,956$ para o conjunto de teste. No entanto, como mostra a Tabela \ref{tab: matriz-confusao-Modelo LogisticRegression}, que exibe a Matriz de confusão para o Modelo LogisticRegression, o resultado não representa bem a realidade.

\input{Tabelas/matriz-confusao-Modelo LogisticRegression}

A Tabela \ref{tab: matriz-confusao-Modelo LogisticRegression} mostra que o modelo atribui erroneamente uma amostra à classe $0$ (majoritária) mais vezes do que à classe $1$ (minoritária).

Esse erro não ocorre somente pela maior presença de dados da classe $0$; a Tabela \ref{tab: classification-report-Modelo LogisticRegression} exibe o \textit{Classification report para o Modelo LogisticRegression} e mostra uma divergência entre as duas classes nas métricas \textit{precision} ($0,95$ para a classe $0$ contra $0,97$ para a classe $1$) e \textit{recall} ($0,99$ para a classe $0$ contra $0,90$ para a classe $1$) e \textit{F-score} ($0,97$ para a classe $0$ contra $0,94$ para a classe $1$).

\input{Tabelas/classification-report-Modelo LogisticRegression}

Intuitivamente, a métrica  \textit{precision} está ligada a habilidade do classificador não classificar como negativa uma amostra que é positiva, enquanto a métrica \textit{recall} demostra a habilidade do classificador em determinar todas as amostras positivas.

O falso negativo (erro do tipo II) é especialmente problemático neste área de aplicação, visto que é preferível alertar erroneamente alguém (por um erro do tipo I, falso positivo), a fim de realizar mais exames, do que deixar de alertar o indivíduo.

A diferença entre as classes dessas métricas indica o que o modelo inteligente "não aprendeu" \ corretamente devido ao problema da base de dados desbalanceada.

\subsection{Exercício iii}

% a Tabela \ref{tab: matriz-confusao-Modelo LogisticRegression}, que exibe a Matriz de confusão para o Modelo LogisticRegression, o resultado não representa bem a realidade.

% \input{Tabelas/matriz-confusao-Modelo LogisticRegression}

% A Tabela \ref{tab: matriz-confusao-Modelo LogisticRegression} mostra que o modelo atribui erroneamente uma amostra a classe $0$ (majoritária) mais vezes do que a classe $1$ (minoritária).

\subsubsection{SVC}

A \textit{accuracy} obtida neste modelo foi de $0,956$ para o conjunto de teste. No entanto, como mostra a Tabela \ref{tab: matriz-confusao-Modelo SVC}, que exibe a Matriz de confusão para o Modelo SVC não otimizado, o modelo atribui erroneamente uma amostra à classe $0$ (majoritária) mais vezes do que à classe $1$ (minoritária).

\input{Tabelas/matriz-confusao-Modelo SVC}

A Tabela \ref{tab: classification-report-Modelo SVC} exibe o \textit{Classification report para o Modelo SVC não otimizado}, que evidência ainda mais que o modelo anterior a diferença entre as métricas \textit{precision} e \textit{recall}.

\input{Tabelas/classification-report-Modelo SVC.tex}

\subsubsection{SVC Otimizado}

A pesquisa em rede determinou $C = 100$ e gamma $ = 0,001$ como parâmetros mais adequados para otimizar a métrica \textit{accuracy} no modelo, cujo valor no conjunto de teste foi $0,965$. 

A Tabela \ref{tab: matriz-confusao-Modelo SVC Otimizado}, que exibe a Matriz de confusão para o Modelo SVC otimizado, também mostra que o modelo atribui erroneamente uma amostra à classe $0$ (majoritária) mais vezes do que à classe $1$ (minoritária).

\input{Tabelas/matriz-confusao-Modelo SVC Otimizado}

A Tabela \ref{tab: classification-report-Modelo SVC Otimizado} exibe o \textit{Classification report para o Modelo SVC Otimizado}. É possível observar uma melhora significativa no modelo SVC através da otimização. As métricas encontram-se mais próximas, mas ainda há diferença especialmente na métrica \textit{recall}.

\input{Tabelas/classification-report-Modelo SVC Otimizado}

\subsubsection{Random Forest}

A \textit{accuracy} obtida neste modelo foi de $0,956$ para o conjunto de teste.

A Tabela \ref{tab: matriz-confusao-Questão III Modelo Random Forest}, que exibe a Matriz de confusão para o Modelo SVC não otimizado, mostra que o modelo também atribui erroneamente uma amostra à classe $0$ (majoritária) mais vezes do que à classe $1$ (minoritária).

\input{Tabelas/matriz-confusao-Questão III Modelo Random Forest}

A Tabela \ref{tab: classification-report-Questão III  Modelo Random Forest} exibe o \textit{Classification report para o Modelo Random Forest}

\input{Tabelas/classification-report-Questão III Modelo Random Forest}

O desempenho do classificador Random Forest é comparável ao da regressão logística.

Dessa forma, podemos concluir que o problema das bases de dados desbalanceadas afetaram todos os modelos inteligentes testados. O efeito foi um pouco mitigado na SVM Otimizada, mas ainda assim estava presente. Desta forma, torna-se interessante investigar mais o problema do desbalanço.


\subsection{Exercício iv}

O percentual de instâncias pertencentes a primeira classe (com $357$ dados) do total de $397$ amostras é de $89,92\%$.

A \textit{accuracy} obtida para o modelo baseado em regressão logística para esse conjunto de dados reduzido e ainda mais desbalanceado foi de $0,963$ para o conjunto de teste, similar (um pouco superior) ao \textit{Exercício ii}, com o conjunto de dados original. A Tabela \ref{tab: matriz-confusao-Modelo LogisticRegression IV} mostra a matriz de confusão para o modelo.

\input{Tabelas/matriz-confusao-Modelo LogisticRegression IV}

A Tabela \ref{tab: classification-report-Modelo LogisticRegression IV} exibe o \textit{Classification report para o Modelo LogisticRegression} do \textit{Exercício iv}. Ela evidencia a degradação da performance que não era visível observando-se a \textit{accuracy}. A distância entre as métricas \textit{recall} e \textit{F-score} está ainda maior para as duas classes.

\input{Tabelas/classification-report-Modelo LogisticRegression IV.tex}

\subsection{Exercício v}

\subsubsection{80 amostras Classe 1}

O percentual de instâncias pertencentes a primeira classe (com $357$ dados) do total de $437$ amostras é de $81,69\%$.

A \textit{accuracy} obtida para o modelo baseado em regressão logística para esse conjunto de dados reduzido e ainda mais desbalanceado foi de $0,955$ para o conjunto de teste, similar ao \textit{Exercício ii}, com o conjunto de dados original. A Tabela \ref{tab: matriz-confusao-Modelo LogisticRegression V - 80} exibe a Matriz de confusão para o Modelo LogisticRegression V - $80$, onde $80$ indica a quantidade de dados da classe $1$.

\input{Tabelas/matriz-confusao-Modelo LogisticRegression V - 80}

A Tabela \ref{tab: classification-report-Modelo LogisticRegression V - 80} exibe o \textit{Classification report para o Modelo LogisticRegression V - $80$ }. É possível observar uma melhora em relação ao modelo do \textit{Exercício iv}. As métricas encontram-se mais próximas, mas ainda há diferença especialmente na métrica \textit{recall} e \textit{f-score}.

\input{Tabelas/classification-report-Modelo LogisticRegression V - 80.tex}

\subsubsection{120 amostras Classe 1}

O percentual de instâncias pertencentes a primeira classe (com $357$ dados) do total de $477$ amostras é de $74,84\%$.

A \textit{accuracy} obtida para o modelo baseado em regressão logística para esse conjunto de dados reduzido e ainda mais desbalanceado foi de $0,958$ para o conjunto de teste, similar ao \textit{Exercício ii}, com o conjunto de dados original. A Tabela \ref{tab: matriz-confusao-Modelo LogisticRegression IV - 120} exibe a Matriz de confusão para o Modelo LogisticRegression V - $120$, onde $120$ indica a quantidade de dados da classe $1$.

\input{Tabelas/matriz-confusao-Modelo LogisticRegression IV - 120}

A Tabela \ref{tab: classification-report-Modelo LogisticRegression IV - 120} exibe o \textit{Classification report para o Modelo LogisticRegression V - $120$ }. É possível observar uma melhora em relação ao modelo do \textit{Exercício iv} e ao modelo anterior. As métricas encontram-se mais próximas, mas ainda há diferença especialmente na métrica \textit{recall} e \textit{f-score}.

\input{Tabelas/classification-report-Modelo LogisticRegression IV - 120.tex}

O desempenho, como era de se esperar, é inferior ao do \textit{Exercício ii}, que possui um menor desequilíbrio dos dados. Em conjunto, os exercícios \textit{ii}, \textit{iv} e \textit{v} mostram a tendência de que, quanto menor o desbalanço dos dados, melhor o desempenho do modelo inteligente.

\subsection{Exercício vi - Upsampling da classe minoritária}

Através do Upsampling da classe minoritária, o número da classe 1 passou de $40$ à $357$, totalizando $714$ amostras e um equilíbrio entre as classes. O percentual de instâncias pertencentes a primeira classe é de $50\%$.

A \textit{accuracy} obtida para o modelo baseado em regressão logística para esse conjunto de dados aumentado e não mais desbalanceado foi de $0,958$ para o conjunto de teste, similar ao \textit{Exercício ii}, com o conjunto de dados original. A Tabela \ref{tab: matriz-confusao-Modelo LogisticRegression VI} exibe a Matriz de confusão para o Modelo LogisticRegression.

\input{Tabelas/matriz-confusao-Modelo LogisticRegression VI}

A Tabela \ref{tab: classification-report-Modelo LogisticRegression VI} exibe o \textit{Classification report para o Modelo LogisticRegression} obtido e mostra que o modelo apresenta especialmente a métrica \textit{recall} referente à classe $1$ (minoritária) melhor que o modelo original do \textit{Exercício II} e representa melhor a realidade.

\input{Tabelas/classification-report-Modelo LogisticRegression VI.tex}

\subsection{Exercício vii - Downsampling da classe majoritária}

Através do Downsampling da classe majoritária, o número da classe 0 passou de $357$ à $212$, totalizando $424$ amostras e um equilíbrio entre as classes. O percentual de instâncias pertencentes a primeira classe é de $50\%$.

A \textit{accuracy} obtida para o modelo baseado em regressão logística para esse conjunto de dados aumentado e não mais desbalanceado foi de $0,965$ para o conjunto de teste, similar ao \textit{Exercício ii}, com o conjunto de dados original. No entanto, a Tabela \ref{tab: matriz-confusao-Modelo LogisticRegression VII}, que exibe a Matriz de confusão para o Modelo LogisticRegression, mostra um equilíbrio entre falsos positivos e negativos.

\input{Tabelas/matriz-confusao-Modelo LogisticRegression VII}

A Tabela \ref{tab: classification-report-Modelo LogisticRegression VII} exibe o \textit{Classification report para o Modelo LogisticRegression} obtido e mostra que o modelo apresenta especialmente a métrica \textit{recall} referente à classe $1$ (minoritária) melhor que o modelo original do \textit{Exercício II} e representa melhor a realidade.

\input{Tabelas/classification-report-Modelo LogisticRegression VII.tex}

\subsection{Exercício viii}

A \textit{accuracy} obtida neste modelo foi de $0,853$ para o conjunto de teste.

A Tabela \ref{tab: matriz-confusao-Questão VIII Modelo Random Forest} exibe a Matriz de confusão para o Modelo Random Forest.

\input{Tabelas/matriz-confusao-Questão VIII Modelo Random Forest}

A Tabela \ref{tab: classification-report-Questão VIII  Modelo Random Forest} exibe o \textit{Classification report para o Modelo Random Forest}. É possível observar um diferença significativa entre as métricas para as duas classes, sendo $0$ correspondendo a $<=50$k e $1$ correspondendo a $>50$k.

\input{Tabelas/classification-report-Questão VIII Modelo Random Forest}

A Tabela \ref{tab: matriz-confusao-Questão VIII Modelo Random Forest} e a Tabela Tabela \ref{tab: classification-report-Questão VIII  Modelo Random Forest} evidenciam que o desbalanço da base de dados afetou o modelo de forma significativa.

\subsection{Exercício ix}

\subsubsection{Regressão Logística}

A métrica \textit{accuracy} no conjunto de teste foi $0,793$. 

A Tabela \ref{tab: matriz-confusao-Modelo LogisticRegression IX} exibe a Matriz de confusão para o Modelo LogisticRegression IX.

\input{Tabelas/matriz-confusao-Modelo LogisticRegression IX}

A Tabela \ref{tab: classification-report-Questão IX Modelo SVC Otimizado} exibe o \textit{Classification report para o Questão IX Modelo LogisticRegression IX}.

\input{Tabelas/classification-report-Modelo LogisticRegression IX}

A Tabela \ref{tab: matriz-confusao-Modelo LogisticRegression IX} e a Tabela \ref{tab: classification-report-Modelo LogisticRegression IX} evidenciam que o desbalanço da base de dados também afetou o modelo de forma significativa, que possuiu um desempenho inferior a Random Forest. Ambos os modelos foram executados sem execução de optimizações.

\subsubsection{SVC Otimizado}

O desempenho do modelo SVC não otimizado foi significativamente inferior ao modelo otimizado.

A pesquisa em rede determinou $C = 100$ e gamma $ = 11$ como parâmetros mais adequados para otimizar a métrica \textit{accuracy} no modelo, cujo valor no conjunto de teste foi $0,804$. 

A Tabela \ref{tab: matriz-confusao-Questão IX Modelo SVC Otimizado} exibe a Matriz de confusão para o Modelo Random Forest.

\input{Tabelas/matriz-confusao-Questão IX Modelo SVC Otimizado}

A Tabela \ref{tab: classification-report-Questão IX Modelo SVC Otimizado} exibe o \textit{Classification report para o Questão IX Modelo SVC Otimizado}.

\input{Tabelas/classification-report-Questão IX Modelo SVC Otimizado.tex}

A Tabela \ref{tab: matriz-confusao-Questão IX Modelo SVC Otimizado} e a Tabela \ref{tab: classification-report-Questão IX Modelo SVC Otimizado} evidenciam que o desbalanço da base de dados também afetou o modelo de forma significativa, que possuiu um desempenho inferior a Random Forest.

\subsection{Exercício x}

\subsubsection{class\_weight = balanced}

A \textit{accuracy} obtida neste modelo foi de $0,854$ para o conjunto de teste, pouco superior ao modelo do \textit{Exercício iiiv}.

A Tabela \ref{tab: matriz-confusao-X RandomForest class_weight = balanced} exibe a Matriz de confusão para o Modelo Random Forest com \textit{class\_weight = balanced}.

\input{Tabelas/matriz-confusao-X RandomForest class_weight = balanced}

A Tabela \ref{tab: classification-report-X RandomForest class_weight = balanced} exibe o \textit{Classification report para o Modelo Random Forest com class\_weight = balanced}. É possível observar um diferença significativa entre as métricas para as duas classes, sendo $0$ correspondendo a $<=50$k e $1$ correspondendo a $>50$k.

\input{Tabelas/classification-report-X RandomForest class_weight = balanced}

A Tabela \ref{tab: matriz-confusao-X RandomForest class_weight = balanced} e a Tabela \ref{tab: classification-report-X RandomForest class_weight = balanced} evidenciam que o desbalanço da base de dados continua a afetar o modelo de forma significativa.

\subsubsection{class\_weight = balanced\_subsample}

A \textit{accuracy} obtida neste modelo foi de $0,857$ para o conjunto de teste, pouco superior ao modelo do \textit{Exercício iiiv} e ao modelo anterior.

A Tabela \ref{tab: matriz-confusao-X RandomForest class_weight = balanced_subsample} exibe a Matriz de confusão para o Modelo Random Forest com \textit{class\_weight = balanced\_subsample}.

\input{Tabelas/matriz-confusao-X RandomForest class_weight = balanced_subsample}

A Tabela \ref{tab: classification-report-X RandomForest class_weight = balanced_subsample} exibe o \textit{Classification report para o Modelo Random Forest com class\_weight = balanced\_subsample}. É possível observar um diferença significativa entre as métricas para as duas classes, sendo $0$ correspondendo a $<=50$k e $1$ correspondendo a $>50$k.

\input{Tabelas/classification-report-X RandomForest class_weight = balanced_subsample}

A Tabela \ref{tab: matriz-confusao-X RandomForest class_weight = balanced_subsample} e a Tabela \ref{tab: classification-report-X RandomForest class_weight = balanced_subsample} evidenciam que o desbalanço da base de dados continua a afetar o modelo de forma significativa.

Para este modelo com esse conjunto de dados, a técnica de atribuição de uma penalidade a cada previsão errada sobre a classe minoritária não se mostrou tão vantajosa. Assim sendo, torna-se interessante averiguar o uso de estratégias de resampling.